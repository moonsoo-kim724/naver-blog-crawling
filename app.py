import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from urllib.parse import quote

class NaverBlogCrawler:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
        }

    def search_blogs(self, keyword, post_count=30):
        results = []
        encoded_keyword = quote(keyword)
        url = f'https://search.naver.com/search.naver?ssc=tab.blog.all&sm=tab_jum&query={encoded_keyword}'
        
        try:
            response = requests.get(url, headers=self.headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            blog_lists = soup.select('div.api_subject_bx ul > li')
            
            for blog in blog_lists[:post_count]:
                try:
                    # ë§í¬ ì¶”ì¶œ
                    title_element = blog.select_one('div.detail_box > div.title_area > a')
                    link = title_element.get('href') if title_element else ''
                    
                    # ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì´ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°
                    if not link or 'blog.naver.com' not in link:
                        continue
                    
                    # ì œëª© ì¶”ì¶œ
                    title = ''.join(title_element.stripped_strings) if title_element else ''
                    
                    # ì‘ì„±ì ì¶”ì¶œ
                    author_element = blog.select_one('div.user_box > div.user_box_inner > div > a')
                    author = author_element.text.strip() if author_element else ''
                    
                    # ì‘ì„±ì¼ ì¶”ì¶œ
                    date_element = blog.select_one('div.user_box > div.user_box_inner > div > span')
                    date = date_element.text.strip() if date_element else ''
                    
                    # ë³¸ë¬¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                    content = self.get_blog_content(link)
                    
                    blog_data = {
                        'ë²ˆí˜¸': len(results) + 1,
                        'ì œëª©': title,
                        'ì‘ì„±ì': author,
                        'ì‘ì„±ì¼': date,
                        'ë§í¬': link,
                        'ë³¸ë¬¸': content
                    }
                    
                    results.append(blog_data)
                    
                except Exception as e:
                    st.error(f"ë¸”ë¡œê·¸ í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    continue
                    
        except Exception as e:
            st.error(f"í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            
        return pd.DataFrame(results)

    def get_blog_content(self, url):
        try:
            # ë¸”ë¡œê·¸ URLì„ ëª¨ë°”ì¼ ë²„ì „ìœ¼ë¡œ ë³€ê²½
            if 'blog.naver.com' in url:
                url = url.replace('blog.naver.com', 'm.blog.naver.com')
            
            response = requests.get(url, headers=self.headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            if 'm.blog.naver.com' in url:
                # ë³¸ë¬¸ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì»´í¬ë„ŒíŠ¸ë“¤ ì¶”ì¶œ
                main_container = soup.select_one('#viewTypeSelector > div > div.se-main-container')
                if main_container:
                    # í…ìŠ¤íŠ¸ ì»´í¬ë„ŒíŠ¸ì™€ ì´ë¯¸ì§€ ì„¤ëª… ëª¨ë‘ ì¶”ì¶œ
                    text_components = main_container.select('div.se-component.se-text, div.se-component.se-image div.se-caption')
                    content = '\n\n'.join([comp.text.strip() for comp in text_components if comp.text.strip()])
                    return content
                else:
                    # êµ¬ë²„ì „ ë¸”ë¡œê·¸ í˜•ì‹ ì²˜ë¦¬
                    old_content = soup.select_one('div#viewTypeSelector, div.se_component_wrap')
                    if old_content:
                        return old_content.text.strip()
            
            return ''
            
        except Exception as e:
            st.error(f"ë¸”ë¡œê·¸ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            return ''

def main():
    st.set_page_config(page_title="ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ë¡¤ëŸ¬", page_icon="ğŸ“", layout="wide")
    
    st.title("ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ë¡¤ë§ ì„œë¹„ìŠ¤")
    st.markdown("""
    í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ ë„¤ì´ë²„ ë¸”ë¡œê·¸ì˜ ê²Œì‹œê¸€ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    ìˆ˜ì§‘ëœ ë°ì´í„°ëŠ” CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    
    st.markdown("### ğŸ“Œ ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥ì°½ì— ì…ë ¥í•˜ì„¸ìš”.
    2. ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.
    3. 'ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.
    4. í¬ë¡¤ë§ì´ ì™„ë£Œë˜ë©´ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    âš ï¸ ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì´ ì•„ë‹Œ ê²Œì‹œê¸€ì€ ì œì™¸í•˜ê³  ìˆ˜ì§‘í•˜ë¯€ë¡œ, ìš”ì²­í•˜ì‹  ìˆ˜ì§‘ ìˆ˜ëŸ‰ê³¼ ì‹¤ì œ ìˆ˜ì§‘ëœ ìˆ˜ëŸ‰ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    
    keyword = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”", "")
    num_posts = st.slider("ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜", min_value=1, max_value=50, value=30)
    
    if st.button("ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘"):
        if keyword:
            try:
                crawler = NaverBlogCrawler()
                with st.spinner('ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                    df = crawler.search_blogs(keyword, num_posts)
                    
                st.success(f'ì´ {len(df)}ê°œì˜ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!')
                
                st.dataframe(df)
                
                csv = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f'naver_blog_{keyword}.csv',
                    mime='text/csv'
                )
                
            except Exception as e:
                st.error(f'ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}')
        else:
            st.warning('í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
    
    st.markdown("---")
    st.markdown("Â© 2024 ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ë¡¤ë§ ì„œë¹„ìŠ¤")

if __name__ == "__main__":
    main() 